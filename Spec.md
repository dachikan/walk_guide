# Walk Guide - 視覚障害者向け散歩案内アプリ

## プロジェクト概要

### プロジェクト名
Walk Guide - 視覚障害者のためのスマ散歩案内アプリ

### 用途説明
視覚障害者の方が安全に歩道を歩行できるよう支援するスマートフォンアプリケーションです。胸部に装着したスマートフォンで前方を数秒ごとに自動撮影し、AI画像解析により障害物・危険物・ランドマークを検出して音声で案内します。

### 現在のバージョン
**v1.2.2+10** (2026年2月15日現在)

### 使用方法
- スマートフォンを前方に向けて胸部に装着
- 5秒間隔で自動撮影・解析を実行
- 音声による結果通知と利用者からの音声コマンドに対応
- フルスクリーン表示で100%カメラ画面を活用

### 開発環境
- **開発OS**: Windows
- **開発言語**: Dart
- **フレームワーク**: Flutter 3.11.0+
- **AI**: マルチAI対応（Gemini・Claude・ChatGPT）
- **対象プラットフォーム**: Android, iOS（安価な中古端末対応）

## 主要機能

### 1. マルチAI画像解析システム 🤖
**対応AIサービス:**
- **Google Gemini** (gemini-2.5-flash-lite): 標準・高速・無料枚数が多い【デフォルト】
- **Claude** (claude-sonnet-4-5-20250929): 高品質・日本語が得意
- **ChatGPT** (gpt-4o): 安定性高・実績豊富

**解析機能:**
- 5秒間隔でカメラから画像を自動取得
- AIによる高精度な画像認識
- 障害物・危険物・ランドマークの瞬時判定
- 距離と方向の詳細な位置情報取得

### 2. 音声案内システム 🔊
**基本案内パターン:**
- **前方OK**: 安全な状況をお知らせ
- **前方危険**: 危険な状況を警告
- **前方○時の方向△m先に□があります**: 障害物の具体的な位置を指示

**詳細案内例:**
- 「前方30m先に信号のある交差点」（ランドマーク検出）
- 「電柱が2時の方向5m先にあるので注意」（危険物警告）
- FlutterTTSによる自然な日本語音声読み上げ

### 3. 高度な音声コマンド機能 🎤
**音声操作:** 
- 右下の浮動ボタンをタップ
- **画面全体どこでもタッチ可能**（視覚障害者に優しい設計）
- タッチで音声コマンド入力モードに切り替え

#### AIサービス変更コマンド
- 「ジェミニ」「ジェミニに変えて」→ Google Gemini AIに切り替え
- 「クロード」「クロードに変えて」→ Claude AIに切り替え  
- 「GPT」「ジーピーティー」「ChatGPTに変えて」→ ChatGPT AIに切り替え

#### 詳細説明コマンド
- 「景色」「説明」「前方」「見える」「どんな」「詳しく」
  → 直前に撮影した画像の詳細説明を実行

#### ヘルプコマンド
- 「略語」「りゃくご」「ヘルプ」「help」
  → 利用可能な音声コマンド一覧を音声で案内

**音声認識の特徴:**
- 日本語音声認識（ja-JP）
- 10秒間のリスニング時間
- 部分結果とノイズフィルタリング対応
- 「アスタリスク」等の誤認識を自動除外

### 4. フルスクリーンUI設計 📱
**画面構成:**
- カメラ画面100%表示（空白エリアなし）
- 左上オーバーレイ：AI情報・解析状況表示
- 右下浮動ボタン：音声コマンド入力
- 画面全体タッチ：音声認識開始/停止（視覚障害者配慮）
- リアルタイム状態インジケーター

**UI状態表示:**
- 🔵青ボタン: 通常状態（音声認識利用可能・自動解析中・割り込み可能）
- 🔴赤ボタン: 命令実行中（音声認識・コマンド処理・割り込み禁止）
- 設定メニュー: AI選択ダイアログ（介助者操作中・割り込み禁止）

**割り込み制御仕様:**
- **通常状態（青ボタン）**: 「前方OK」等の自動解析を音声コマンドで割り込み可能
- **命令実行中（赤ボタン）**: 詳細説明等のコマンド完了まで自動解析完全停止
- **設定操作中**: 介助者によるAI変更時は全ての音声操作を無効化

### 5. フォールバック機能
- カメラが利用できない環境でも動作
- 画像選択による手動解析機能
- エラー時の適切なフィードバック
- 音声認識エラー時の自動回復機能

## 技術仕様

### 依存パッケージ
```yaml
dependencies:
  flutter_dotenv: ^5.1.0       # 環境変数管理
  google_generative_ai: ^0.4.0 # Gemini API連携  
  camera: ^0.11.0              # カメラ制御
  flutter_tts: ^4.2.2          # 音声読み上げ
  speech_to_text: ^7.0.0       # 音声認識・音声コマンド処理
  image_picker: ^1.0.4         # 画像選択機能
  package_info_plus: ^4.2.0    # アプリバージョン情報取得
  http: ^1.6.0                 # HTTP リクエスト用（Claude, ChatGPT API）
  shared_preferences: ^2.2.2   # AI選択設定保存用
```

### 環境設定
```env
# .walking_guide.env ファイル
GEMINI_API_KEY=your_gemini_api_key_here
CLAUDE_API_KEY=your_claude_api_key_here  
OPENAI_API_KEY=your_openai_api_key_here
```

### アーキテクチャ特徴
- **マルチAI対応**: 3つのAIサービスを統一インターフェースで管理
- **エラーハンドリング**: 堅牢な例外処理とフォールバック機能
- **非同期処理**: Futureを活用した効率的な処理
- **ステート管理**: StatefulWidgetによるリアクティブUI
- **タイマー制御**: 定期実行による自動解析
- **権限管理**: カメラ・マイク権限の適切な処理

## ユーザーインターフェース

### メイン画面の構成
```
┌─────────────────────────────────┐
│  ■ AI: Gemini  自動解析中(5s間隔) │ ← 左上情報オーバーレイ
│                                 │
│                                 │
│         カメラ画面100%             │
│        (フルスクリーン)            │
│           画面全体タップ可能         │
│                                 │
│                          🎤    │ ← 右下音声ボタン
│                       命令実行中 │ ← 状態表示
└─────────────────────────────────┘
```

### 設定画面
- AIサービス選択ダイアログ
- 各AIサービスの特徴説明付き
- ラジオボタンによる選択UI

### メイン画面
- **カメラ利用可能時**: カメラプレビュー + 自動解析状態表示
- **カメラ非対応時**: 画像選択ボタンによるフォールバック画面
- 直感的でアクセシブルなデザイン

### 音声フィードバック
- 視覚に依存しない音声中心のUI/UX
- 短時間で理解できる簡潔な音声メッセージ
- エラー時も適切な音声案内

## セキュリティ・プライバシー
- APIキーの安全な管理
- 画像データの適切な処理（一時的な使用のみ）
- ローカル処理とクラウドAPIのバランス

## AI プロンプト設計

### 基本プロンプト構造
```
前方に進んでも良ければ「前方OK」と知らせて下さい。
障害物があれば「前方○時の方向△m先に□があります」と知らせて下さい。
このまま進めばx秒以内に問題発生の可能性があれば「前方危険」と知らせて下さい。
```

### プロンプト改善プロセス
- 継続的な試行とフィードバック収集
- 実環境でのテストによる精度向上
- 利用者のニーズに基づく調整

## AI API設計とプロンプト

### 基本プロンプト（自動解析用）
```
あなたは視覚障害者の歩行支援AIです。画像を見て、前方の状況を
「前方OK」「前方危険」、または障害物の位置を「○時の方向」で短く答えてください。
```

### 詳細プロンプト（音声コマンド用）
```
目の不自由な方のための詳細な風景説明をお願いします。
前方に見える景色、道の状況、障害物、建物、人、車両、信号機、標識など、
すべての重要な情報を具体的に日本語で説明してください。
```

### AI APIエンドポイント
- **Gemini**: `gemini-2.5-flash-lite` モデル
- **Claude**: `claude-sonnet-4-5-20250929` モデル  
- **ChatGPT**: `gpt-4o` モデル

## セキュリティ・プライバシー
- APIキーの安全な環境変数管理
- 画像データの適切な処理（一時的な使用のみ）
- ローカル処理とクラウドAPIのバランス
- 権限管理の実装（カメラ・マイク）

## プロジェクト構成とファイルの役割

### 主要ファイル一覧

#### 1. プロジェクト設定・構成ファイル
- **pubspec.yaml** 📋
  - **役割**: プロジェクト全体の設定ファイル（バージョン: v1.2.2+10）
  - **内容**: アプリ名、バージョン、使用するパッケージ（ライブラリ）の指定
  - **重要**: マルチAI対応のための依存パッケージ管理

- **.walking_guide.env** 🔐
  - **役割**: APIキー等の機密情報管理
  - **内容**: Gemini, Claude, OpenAI APIキーを安全に保存
  - **セキュリティ**: gitignoreで除外、外部流出防止

#### 2. プログラムコードファイル
- **lib/main.dart** 💻 (625行)
  - **役割**: アプリケーションのメインプログラム
  - **主要機能**: 
    * マルチAI画像解析エンジン
    * 音声認識・コマンド処理システム
    * フルスクリーンカメラUI制御
    * タイマーベースの自動解析ループ
    * エラーハンドリングとフォールバック処理

#### 3. プラットフォーム設定ファイル
- **android/app/src/main/AndroidManifest.xml** 🔧
  - **役割**: Android固有の設定とパーミッション定義
  - **内容**: カメラ・マイク使用権限、アプリ名、アイコン設定
  - **内容**: カメラ制御、AI解析、音声出力等の全ての機能のプログラムコード
  - **言語**: Dart言語で記述されている
  - **重要度**: ★★★（最も重要なファイル）

#### 3. 環境設定ファイル
- **.walking_guide.env** 🔐
  - **役割**: 秘密情報（APIキー）の保管
  - **内容**: Gemini AIを使用するためのAPIキー
  - **セキュリティ**: パスワードのような機密情報のため、他人と共有禁止

#### 4. ドキュメントファイル
- **README.md** 📖
  - **役割**: プロジェクトの基本説明
  - **内容**: アプリの概要、インストール方法の簡単な説明
  
- **Spec.md** 📝
  - **役割**: 詳細仕様書（この文書）
  - **内容**: アプリの機能、技術仕様、開発プロセスの詳細

#### 5. プラットフォーム別設定フォルダ
- **android/** 🤖
  - **役割**: Android端末用の設定ファイル群
  - **内容**: アプリ権限、アイコン、Android特有の設定
  
- **ios/** 🍎
  - **役割**: iPhone/iPad用の設定ファイル群
  - **内容**: iOS特有の設定、App Store用情報
  
- **windows/** 🪟 / **web/** 🌐 / **linux/** 🐧
  - **役割**: その他のプラットフォーム用設定

#### 6. ビルド結果フォルダ
- **build/** 📦
  - **役割**: コンパイル（ビルド）結果の保存場所
  - **内容**: APKファイル（Android用インストールファイル）
  - **重要**: `build/app/outputs/flutter-apk/app-debug.apk` が実際にスマホにインストールするファイル

#### 7. テストファイル
- **test/** 🧪
  - **役割**: プログラムの動作テスト用コード
  - **内容**: アプリが正しく動作するかを確認するための自動テスト

### ファイル間の関係性

```
pubspec.yaml（設定） → lib/main.dart（実行）
                    ↓
.walking_guide.env（APIキー） → Gemini AI連携
                    ↓
            build/（ビルド結果）
                    ↓
            app-debug.apk（スマホ用ファイル）
```

### 開発の流れ

1. **設計**: Spec.mdで機能を定義
2. **設定**: pubspec.yamlで必要なパッケージを指定
3. **プログラミング**: lib/main.dartでコードを記述
4. **ビルド**: プログラムをAPKファイルに変換
5. **インストール**: スマートフォンにAPKをインストール
6. **テスト**: 実際の動作を確認・改善

### 初心者向け重要ポイント

- **最も重要**: `lib/main.dart`（アプリの動作はここで決まる）
- **設定重要**: `pubspec.yaml`（機能追加時に必ず編集）
- **機密管理**: `.walking_guide.env`（APIキーは絶対に他人と共有しない）
- **実行ファイル**: `build/app/outputs/flutter-apk/app-debug.apk`（これをスマホにインストール）

## Dart言語について（C#プログラマー向け）

### DartとC#の共通点 ✅

**C#をご存知でしたら、Dartは非常に習得しやすい言語です！**

#### 1. **基本構文が類似**
```dart
// Dart
class WalkingGuideApp {
  String appName = "Walk Guide";
  int version = 1;
  
  void showMessage() {
    print("Hello, $appName!");
  }
}
```

```csharp
// C# (参考)
class WalkingGuideApp {
  string appName = "Walk Guide";
  int version = 1;
  
  void ShowMessage() {
    Console.WriteLine($"Hello, {appName}!");
  }
}
```

#### 2. **オブジェクト指向プログラミング**
- **クラス・継承・インターフェース**: C#と同じ概念
- **コンストラクタ**: `ClassName(parameters)` 形式
- **メソッド・プロパティ**: C#と同様の書き方

#### 3. **静的型付け言語**
- **型安全**: コンパイル時にエラー検出（C#と同じ）
- **IntelliSense**: Visual Studioと同様の自動補完
- **null安全性**: C# 8.0以降のnullable参照型と類似

#### 4. **非同期処理**
```dart
// Dart
Future<String> analyzeImage() async {
  var result = await geminiAPI.generateContent(image);
  return result.text;
}
```

```csharp
// C# (参考)
async Task<string> AnalyzeImage() {
  var result = await geminiAPI.GenerateContentAsync(image);
  return result.Text;
}
```
**`async/await`パターンが全く同じ！**

#### 5. **ガベージコレクション**
- **メモリ管理**: C#と同様に自動メモリ管理
- **オブジェクト生成・破棄**: 手動管理不要

### DartとC#の主な違い 📝

| 項目 | C# | Dart |
|------|----|----- |
| **null許容型** | `string?` | `String?` |
| **文字列補間** | `$"{variable}"` | `"$variable"` または `"${expression}"` |
| **命名規則** | `PascalCase` (メソッド) | `camelCase` (メソッド) |
| **プリミティブ型** | `int, string, bool` | `int, String, bool` |
| **配列・リスト** | `List<T>, T[]` | `List<T>` (主にこれ) |
| **プロパティ** | `get; set;` | `get => value;` |

### 実際のコード比較例

#### **C#っぽい書き方 (馴染みやすい)**
```dart
class CameraController {
  bool _isInitialized = false;
  Timer? _timer;
  
  Future<void> initializeCamera() async {
    try {
      // カメラ初期化処理
      _isInitialized = true;
      _timer = Timer.periodic(Duration(seconds: 5), (timer) {
        analyzeScene();
      });
    } catch (e) {
      print('Camera initialization failed: $e');
    }
  }
  
  void dispose() {
    _timer?.cancel();
  }
}
```

#### **特徴的なDart記法 (慣れが必要)**
```dart
// Widget (UI要素) の宣言
Widget build(BuildContext context) {
  return Scaffold(
    appBar: AppBar(title: Text('歩道案内')),
    body: _cameraAvailable 
      ? CameraPreview(_controller!)
      : Center(child: Text('カメラが利用できません')),
  );
}
```

### 学習の進め方（C#経験者向け）

#### **1週目**: 基本構文理解
- **変数宣言**: `var`, `final`, `const`の使い分け
- **関数定義**: `void`, `Future<T>`の違い
- **null安全性**: `?`と`!`演算子

#### **2週目**: Flutterの概念理解
- **Widget**: C#のUserControlに相当
- **State管理**: MVVMパターンと類似
- **非同期処理**: Task/async patternと同じ

#### **3週目**: 実践的な開発
- **パッケージ管理**: NuGetと`pubspec.yaml`
- **ビルドプロセス**: Visual Studioと`flutter build`
- **デバッグ**: F5実行と`flutter run`

### C#プログラマーの利点

**✅ 既存知識が活用できる部分:**
- オブジェクト指向設計パターン
- MVVM・MVC等のアーキテクチャパターン  
- 例外処理・エラーハンドリング
- 非同期プログラミングの概念
- 型システムの理解

**🔧 新しく覚える必要がある部分:**
- Widget木構造（HTMLのDOMに近い）
- State管理（Flutterのライフサイクル）
- `pubspec.yaml`でのパッケージ管理

### 結論

**DartはC#経験者にとって非常に習得しやすい言語です！**  
構文・概念の80%以上がC#と共通しており、Flutterの特殊な部分（Widget等）さえ理解すれば、すぐに実用的なアプリ開発が可能です。

## バージョン履歴

### v1.2.5+13 (2026年2月15日) - 最新版 🎉
**重要な修正:**
- ✅ 音声認識とTTS競合問題の修正
- ✅ 音声コマンド入力中は自動解析の音声出力を停止
- ✅ 「前方OK」等の音声が音声認識を妨害しない仕組み
- ✅ 画像解析は継続、結果はログで確認可能

**共存機能:**
- ✅ マルチAI対応（Gemini・Claude・ChatGPT）
- ✅ フルスクリーンカメラ表示（100%活用）
- ✅ 高度な音声コマンド機能
- ✅ 「略語」ヘルプコマンド
- ✅ 誤認識フィルタリング機能

### v1.2.4+12 (2026年2月15日)
**修正:**
- ✅ 音声コマンドフィルタリング緩和
- ✅ 「アスタリスク」誤認識問題解決

### v1.2.3+11 (2026年2月15日) - 問題版
**問題:**
- ❌ 過度なフィルタリングで音声コマンドが効かない
- ❌ 「アスタリスク」誤認識多発

### v1.2.2+10 (2026年2月15日)
**追加機能:**
- ✅ 音声認識デバッグ機能強化
- ✅ 詳細な状態表示とエラーハンドリング

### v1.1.3+7 (2026年2月14日)
**追加機能:**
- ✅ Claude API統合 (claude-sonnet-4-5-20250929)
- ✅ ChatGPT API統合 (gpt-4o)
- ✅ AI選択UI・設定保存機能

### v1.0.0+1 (2026年2月13日)
**基本機能:**
- ✅ 基本的なカメラ撮影・画像解析機能
- ✅ Gemini API統合
- ✅ 音声読み上げ機能

## 今後の展開予定
- 🚧 GPS連携によるランドマーク情報補強
- 🚧 学習機能による個人最適化
- 🚧 オフライン画像解析モード
- 🚧 多言語対応（英語・中国語）
- 🚧 ウェアラブルデバイス対応

## 開発メトリクス
- **総開発期間**: 3日間（アクティブ開発）
- **総コード行数**: 約700行（main.dart）
- **対応プラットフォーム**: Android（iOS対応準備中）
- **テスト端末**: HUAWEI nova (GGXDU17227002711)

---

**最新バージョン**: v1.2.2+10  
**開発開始**: 2026年2月13日  
**最終更新**: 2026年2月15日  
**開発状況**: アクティブ開発中・安定稼働